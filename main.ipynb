{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install backtrader riskfolio yfinance ta-lib kagglehub\n",
    "%pip install pandas numpy matplotlib mplfinance gym stable-baselines3 tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Manipulation and Analysis Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install talib\n",
    "\n",
    "import pandas as pd  # Data manipulation and analysis\n",
    "import numpy as np  # Numerical operations\n",
    "import matplotlib.pyplot as plt  # Plotting and visualization\n",
    "import mplfinance as mpl  # Financial data plotting\n",
    "import yfinance as yf # Yahoo Finance API\n",
    "import talib as ta  # Technical analysis library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforement Learning Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install stable-baselines3 package\n",
    "%pip install stable-baselines3 gym\n",
    "from stable_baselines3.common.evaluation import evaluate_policy  # Evaluate model\n",
    "\n",
    "import gym\n",
    "from stable_baselines3 import PPO  # Proximal Policy Optimization algorithm\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv  # Vectorized environment\n",
    "from stable_baselines3.common.callbacks import EvalCallback  # Evaluation callback\n",
    "from stable_baselines3.common.env_checker import check_env  # Check environment\n",
    "\n",
    "# Install stable-baselines3 package\n",
    "%pip install stable-baselines3\n",
    "from stable_baselines3.common.evaluation import evaluate_policy  # Evaluate model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler  # Standardizing features by removing the mean and scaling to unit variance\n",
    "from sklearn.preprocessing import MinMaxScaler  # Scaling features to a range (default is 0 to 1) or custom range (min and max)\n",
    "from sklearn.preprocessing import RobustScaler  # Scaling features using statistics that are robust to outliers\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier  # Random forest classifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error  # Accuracy classification score\n",
    "from sklearn.metrics import classification_report, confusion_matrix  # Classification report and confusion matrix\n",
    "from sklearn.metrics import roc_curve, roc_auc_score  # ROC curve and ROC AUC score\n",
    "\n",
    "from sklearn.model_selection import train_test_split  # Splitting data into training and testing sets\n",
    "from sklearn.model_selection import RandomizedSearchCV  # Randomized search on hyperparameters\n",
    "from sklearn.model_selection import cross_val_score  # Cross validation score\n",
    "from sklearn.model_selection import TimeSeriesSplit  # Time Series split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Llbraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf  # Deep learning framework (alternatively, you can use PyTorch)\n",
    "import torch \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = yf.download(\"GOOG\", start=\"2010-01-01\", end=\"2021-01-01\")\n",
    "\n",
    "\n",
    "for i in [5,10,15,20,50,100]:\n",
    "    data['sma'+str(i)] = data['Close'].rolling(window=i).mean()\n",
    "    data['ema'+str(i)] = data['Close'].ewm(span=i, adjust=False).mean()\n",
    "    data['momentum'+str(i)] = data['Close']-data['Close'].shift(i)\n",
    "    data['rsi'+str(i)] = ta.momentum.rsi(data['Close'], n=i, fillna=True)\n",
    "    data['macd'+str(i)] = ta.trend.macd(data['Close'], n_fast=i, n_slow=2*i, fillna=True)\n",
    "    data['atr'+str(i)] = ta.volatility.average_true_range(data['High'], data['Low'], data['Close'], n=i, fillna=True)\n",
    "    data['bollinger_up'+str(i)] = ta.volatility.bollinger_hband(data['Close'], n=i, ndev=2, fillna=True)\n",
    "    data['bollinger_down'+str(i)] = ta.volatility.bollinger_lband(data['Close'], n=i, ndev=2, fillna=True)\n",
    "   \n",
    "\n",
    "data['returns'] = data['Close'].pct_change()\n",
    "data['direction'] = np.where(data['returns'] > 0, 1, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data['Close'], label='Close Price')\n",
    "plt.plot(data['sma5'], label='SMA 5')\n",
    "\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.title(\"Stock Price with SMA 5\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking for accuracy score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data.dropna().drop(['Close'], axis=1)\n",
    "target = np.where(data['Close'].shift(-1) > data['Close'], 1, -1)  # Target variable\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Standardizing the features\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# Training the random forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Calculating the mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print('Mean Squared Error:', mse)\n",
    "\n",
    "# Calculating the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networking Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class torch_bot():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tensor_bot():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequences for training\n",
    "def create_sequences(data: pd.DataFrame, seq_length: int)-> np.array:\n",
    "  sequences = []\n",
    "  for i in range(len(data) - seq_length):\n",
    "       sequences.append(data[i:i+seq_length])\n",
    "\n",
    "  return np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the data\n",
    "data = yf.download(\"AAPL\", start = \"2010-01-01\", end = \"2019-12-31\")\n",
    "scaler = MinMaxScaler(feature_range = (0,1))\n",
    "scaled_data = scaler.fit_transform(data['Close'].values.reshape(-1,1))\n",
    "\n",
    "# Prepare the training and test datasets\n",
    "train_size = int(len(scaled_data) * 0.8)\n",
    "train_data = scaled_data[:train_size]\n",
    "test_data = scaled_data[train_size:]\n",
    "\n",
    "# Build the LSTM Model\n",
    "seq_length = 60\n",
    "X_train = create_sequences(train_data, seq_length)\n",
    "X_test = create_sequences(test_data, seq_length)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(units = 50, return_sequences = True, input_shape = (seq_length, 1)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units = 50, return_sequences = False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units = 1))\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, train_data[seq_length:], batch_size = 32, epochs = 5)\n",
    "\n",
    "# Predict stock prices\n",
    "X_test = create_sequences(test_data, seq_length)\n",
    "predictions = model.predict(X_test)\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "\n",
    "print(pd.DataFrame(predictions).describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcment Learning Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RL_Bot(gym.env):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qlearning_bot(gym.env, RL_Bot):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-Time Data Extraction and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
